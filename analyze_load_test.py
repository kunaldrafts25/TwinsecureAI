#!/usr/bin/env python
"""
Load test results analyzer.
This script analyzes the CSV files generated by Locust load tests.
"""

import argparse
import os
import sys
from pathlib import Path

try:
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
except ImportError:
    print("Required packages not found. Installing...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "pandas", "matplotlib", "seaborn"])
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns


def load_data(prefix="load_test_results"):
    """
    Load the CSV files generated by Locust.
    
    Args:
        prefix (str): The prefix of the CSV files
    
    Returns:
        tuple: (stats_df, history_df, failures_df)
    """
    stats_file = f"{prefix}_stats.csv"
    history_file = f"{prefix}_stats_history.csv"
    failures_file = f"{prefix}_failures.csv"
    
    stats_df = None
    history_df = None
    failures_df = None
    
    if os.path.exists(stats_file):
        stats_df = pd.read_csv(stats_file)
        print(f"Loaded {stats_file}")
    else:
        print(f"Warning: {stats_file} not found")
    
    if os.path.exists(history_file):
        history_df = pd.read_csv(history_file)
        print(f"Loaded {history_file}")
    else:
        print(f"Warning: {history_file} not found")
    
    if os.path.exists(failures_file):
        failures_df = pd.read_csv(failures_file)
        print(f"Loaded {failures_file}")
    else:
        print(f"Warning: {failures_file} not found")
    
    return stats_df, history_df, failures_df


def analyze_stats(stats_df):
    """
    Analyze the stats data.
    
    Args:
        stats_df (DataFrame): The stats data
    """
    if stats_df is None:
        print("No stats data available")
        return
    
    print("\n=== Request Statistics ===")
    
    # Clean up the data
    stats_df = stats_df[stats_df["Name"] != "Aggregated"]
    stats_df["Method"] = stats_df["Name"].str.split().str[0]
    stats_df["Endpoint"] = stats_df["Name"].str.split().str[1]
    
    # Sort by median response time
    stats_df = stats_df.sort_values("Median Response Time", ascending=False)
    
    # Print summary
    print(f"Total Requests: {stats_df['# Requests'].sum()}")
    print(f"Failed Requests: {stats_df['# Failures'].sum()} ({stats_df['# Failures'].sum() / stats_df['# Requests'].sum() * 100:.2f}%)")
    print(f"Average Response Time: {stats_df['Average Response Time'].mean():.2f} ms")
    print(f"Requests per Second: {stats_df['Requests/s'].sum():.2f}")
    
    # Print endpoint stats
    print("\nEndpoint Statistics:")
    for _, row in stats_df.iterrows():
        print(f"{row['Method']} {row['Endpoint']}: {row['# Requests']} requests, {row['# Failures']} failures, {row['Median Response Time']} ms median")
    
    # Create a bar chart of median response times
    plt.figure(figsize=(12, 6))
    sns.barplot(x="Endpoint", y="Median Response Time", hue="Method", data=stats_df)
    plt.title("Median Response Time by Endpoint")
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    plt.savefig("response_times.png")
    print("\nSaved response time chart to response_times.png")


def analyze_history(history_df):
    """
    Analyze the history data.
    
    Args:
        history_df (DataFrame): The history data
    """
    if history_df is None:
        print("No history data available")
        return
    
    print("\n=== Performance Over Time ===")
    
    # Convert timestamp to datetime
    history_df["Timestamp"] = pd.to_datetime(history_df["Timestamp"])
    
    # Filter for Aggregated data
    agg_df = history_df[history_df["Name"] == "Aggregated"]
    
    # Print summary
    print(f"Test Duration: {(agg_df['Timestamp'].max() - agg_df['Timestamp'].min()).total_seconds():.2f} seconds")
    print(f"Peak RPS: {agg_df['Requests/s'].max():.2f}")
    print(f"Peak Failures/s: {agg_df['Failures/s'].max():.2f}")
    
    # Create a line chart of RPS and failures over time
    plt.figure(figsize=(12, 6))
    plt.plot(agg_df["Timestamp"], agg_df["Requests/s"], label="Requests/s")
    plt.plot(agg_df["Timestamp"], agg_df["Failures/s"], label="Failures/s")
    plt.title("Requests and Failures per Second Over Time")
    plt.xlabel("Time")
    plt.ylabel("Rate")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("performance_over_time.png")
    print("\nSaved performance chart to performance_over_time.png")
    
    # Create a line chart of response times over time
    plt.figure(figsize=(12, 6))
    plt.plot(agg_df["Timestamp"], agg_df["Average Response Time"], label="Average")
    plt.plot(agg_df["Timestamp"], agg_df["Median Response Time"], label="Median")
    plt.plot(agg_df["Timestamp"], agg_df["90%ile Response Time"], label="90%ile")
    plt.title("Response Times Over Time")
    plt.xlabel("Time")
    plt.ylabel("Response Time (ms)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("response_times_over_time.png")
    print("\nSaved response time chart to response_times_over_time.png")


def analyze_failures(failures_df):
    """
    Analyze the failures data.
    
    Args:
        failures_df (DataFrame): The failures data
    """
    if failures_df is None or failures_df.empty:
        print("\n=== Failures ===")
        print("No failures recorded")
        return
    
    print("\n=== Failures ===")
    
    # Group by error and count occurrences
    error_counts = failures_df.groupby(["Error"]).size().reset_index(name="Count")
    error_counts = error_counts.sort_values("Count", ascending=False)
    
    # Print summary
    print(f"Total Failures: {error_counts['Count'].sum()}")
    
    # Print error details
    print("\nError Types:")
    for _, row in error_counts.iterrows():
        print(f"{row['Error']}: {row['Count']} occurrences")
    
    # Create a bar chart of error counts
    plt.figure(figsize=(12, 6))
    sns.barplot(x="Error", y="Count", data=error_counts)
    plt.title("Error Counts by Type")
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    plt.savefig("error_counts.png")
    print("\nSaved error chart to error_counts.png")


def main():
    """
    Main function.
    """
    parser = argparse.ArgumentParser(description="Analyze Locust load test results")
    parser.add_argument("--prefix", default="load_test_results", help="Prefix of the CSV files")
    args = parser.parse_args()
    
    print("=== Load Test Results Analysis ===")
    
    # Load the data
    stats_df, history_df, failures_df = load_data(args.prefix)
    
    # Analyze the data
    analyze_stats(stats_df)
    analyze_history(history_df)
    analyze_failures(failures_df)
    
    print("\nAnalysis complete!")


if __name__ == "__main__":
    main()
